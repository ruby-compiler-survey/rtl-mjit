/* -*- mode:c; style:ruby; coding: utf-8 -*-
  insns.def - YARV RTL instruction definitions

  $Author: $
  created at: 04/01/01 01:17:55 JST

  Copyright (C) 2004-2007 Koichi Sasada
  Massive rewrite by @shyouhei in 2017.
  Rewritten in 2018 by Vladimir Makarov <vmakarov@redhat.com> to
  implement RTL insns
 */

/* Some comments about this file's contents:

   - The new format aims to be editable by C editor of your choice;
     your mileage might vary of course.

   - Each instructions are in following format:

     DEFINE_INSN
     instruction_name
     (type operand, type operand, ..)
     (pop_values, ..)
     (return values ..)
     // attr type name contents..
     {
       .. // insn body
     }

   - Unlike the old format which was line-oriented, you can now place
     newlines and comments at liberal positions.

   - `DEFINE_INSN` is a keyword.

   - An instruction name must be a valid C identifier.

   - Operands, pop values, return values are series of either variable
     declarations, keyword `void`, or keyword `...`.  They are much
     like C function declarations.

   - Attribute pragmas are optional, and can include arbitrary C
     expressions.  You can write anything there but as of writing,
     supported attributes are:

       * sp_inc: Used to dynamically calculate sp increase in
         `insn_stack_increase`.

       * handles_sp: If it is true, VM deals with sp in the insn.

       * leaf: indicates that the instruction is "leaf" i.e. it does
         not introduce new stack frame on top of it.  Default true.

   - Attributes can access operands, but not stack (push/pop) variables.

   - An instruction's body is a pure C block, copied verbatimly into
     the generated C source code.
 */

/**********************************************************/
/* deal with variables                                    */
/**********************************************************/

/* Get local variable (pointed by `idx' and `level').
     'level' indicates the nesting depth from the current block.
 */
DEFINE_INSN
getlocal
(lindex_t idx, rb_num_t level)
()
(VALUE val)
{
#if STACK_INSN_CODE
    val = *(vm_get_ep(GET_EP(), level) - idx);
    RB_DEBUG_COUNTER_INC(lvar_get);
    (void)RB_DEBUG_COUNTER_INC_IF(lvar_get_dynamic, level > 0);
#endif
}

/* Set a local variable (pointed to by 'idx') as val.
     'level' indicates the nesting depth from the current block.
 */
DEFINE_INSN
setlocal
(lindex_t idx, rb_num_t level)
(VALUE val)
()
{
#if STACK_INSN_CODE
    vm_env_write(vm_get_ep(GET_EP(), level), -(int)idx, val);
    RB_DEBUG_COUNTER_INC(lvar_set);
    (void)RB_DEBUG_COUNTER_INC_IF(lvar_set_dynamic, level > 0);
#endif
}

/* Get a block parameter. */
DEFINE_INSN
getblockparam
(lindex_t idx, rb_num_t level)
()
(VALUE val)
{
#if STACK_INSN_CODE
    const VALUE *ep = vm_get_ep(GET_EP(), level);
    VM_ASSERT(VM_ENV_LOCAL_P(ep));

    if (!VM_ENV_FLAGS(ep, VM_FRAME_FLAG_MODIFIED_BLOCK_PARAM)) {
	val = rb_vm_bh_to_procval(ec, VM_ENV_BLOCK_HANDLER(ep));
	vm_env_write(ep, -(int)idx, val);
	VM_ENV_FLAGS_SET(ep, VM_FRAME_FLAG_MODIFIED_BLOCK_PARAM);
    }
    else {
	val = *(ep - idx);
	RB_DEBUG_COUNTER_INC(lvar_get);
	(void)RB_DEBUG_COUNTER_INC_IF(lvar_get_dynamic, level > 0);
    }
#endif
}

/* Set block parameter. */
DEFINE_INSN
setblockparam
(lindex_t idx, rb_num_t level)
(VALUE val)
()
{
#if STACK_INSN_CODE
    const VALUE *ep = vm_get_ep(GET_EP(), level);
    VM_ASSERT(VM_ENV_LOCAL_P(ep));

    vm_env_write(ep, -(int)idx, val);
    RB_DEBUG_COUNTER_INC(lvar_set);
    (void)RB_DEBUG_COUNTER_INC_IF(lvar_set_dynamic, level > 0);

    VM_ENV_FLAGS_SET(ep, VM_FRAME_FLAG_MODIFIED_BLOCK_PARAM);
#endif
}

/* Get special proxy object which only responds to `call` method if the block parameter
     represents a iseq/ifunc block. Otherwise, same as `getblockparam`.
 */
DEFINE_INSN
getblockparamproxy
(lindex_t idx, rb_num_t level)
()
(VALUE val)
{
#if STACK_INSN_CODE
    const VALUE *ep = vm_get_ep(GET_EP(), level);
    VM_ASSERT(VM_ENV_LOCAL_P(ep));

    if (!VM_ENV_FLAGS(ep, VM_FRAME_FLAG_MODIFIED_BLOCK_PARAM)) {
	VALUE block_handler = VM_ENV_BLOCK_HANDLER(ep);

	if (block_handler) {
	    switch (vm_block_handler_type(block_handler)) {
	      case block_handler_type_iseq:
	      case block_handler_type_ifunc:
		val = rb_block_param_proxy;
		break;
	      case block_handler_type_symbol:
		val = rb_sym_to_proc(VM_BH_TO_SYMBOL(block_handler));
		goto INSN_LABEL(set);
	      case block_handler_type_proc:
		val = VM_BH_TO_PROC(block_handler);
		goto INSN_LABEL(set);
	      default:
		VM_UNREACHABLE(getblockparamproxy);
	    }
	}
	else {
	    val = Qnil;
	  INSN_LABEL(set):
	    vm_env_write(ep, -(int)idx, val);
	    VM_ENV_FLAGS_SET(ep, VM_FRAME_FLAG_MODIFIED_BLOCK_PARAM);
	}
    }
    else {
	val = *(ep - idx);
	RB_DEBUG_COUNTER_INC(lvar_get);
	(void)RB_DEBUG_COUNTER_INC_IF(lvar_get_dynamic, level > 0);
    }
#endif
}

/* Get value of special local variable ($~, $_, ..). */
DEFINE_INSN
getspecial
(rb_num_t key, rb_num_t type)
()
(VALUE val)
{
#if STACK_INSN_CODE
    val = vm_getspecial(ec, GET_LEP(), key, type);
#endif
}

/* Set value of special local variable ($~, $_, ...) to obj. */
DEFINE_INSN
setspecial
(rb_num_t key)
(VALUE obj)
()
{
#if STACK_INSN_CODE
    lep_svar_set(ec, GET_LEP(), key, obj);
#endif
}

/* Get value of instance variable id of self. */
DEFINE_INSN
getinstancevariable
(ID id, IC ic)
()
(VALUE val)
/* "instance variable not initialized" warning can be hooked. */
// attr bool leaf = false; /* has rb_warning() */
{
#if STACK_INSN_CODE
    val = vm_getinstancevariable(GET_SELF(), id, ic);
#endif
}

/* Set value of instance variable id of self to val. */
DEFINE_INSN
setinstancevariable
(ID id, IC ic)
(VALUE val)
()
{
#if STACK_INSN_CODE
    vm_setinstancevariable(GET_SELF(), id, val, ic);
#endif
}

/* Get value of class variable id of klass as val. */
DEFINE_INSN
getclassvariable
(ID id)
()
(VALUE val)
/* "class variable access from toplevel" warning can be hooked. */
// attr bool leaf = false; /* has rb_warning() */
{
#if STACK_INSN_CODE
    val = rb_cvar_get(vm_get_cvar_base(rb_vm_get_cref(GET_EP()), GET_CFP()), id);
#endif
}

/* Set value of class variable id of klass as val. */
DEFINE_INSN
setclassvariable
(ID id)
(VALUE val)
()
/* "class variable access from toplevel" warning can be hooked. */
// attr bool leaf = false; /* has rb_warning() */
{
#if STACK_INSN_CODE
    vm_ensure_not_refinement_module(GET_SELF());
    rb_cvar_set(vm_get_cvar_base(rb_vm_get_cref(GET_EP()), GET_CFP()), id, val);
#endif
}

/* Get constant variable id. If klass is Qnil, constants
   are searched in the current scope. Otherwise, get constant under klass
   class or module.
 */
DEFINE_INSN
getconstant
(ID id)
(VALUE klass)
(VALUE val)
/* getconstant can kick autoload */
// attr bool leaf = false; /* has rb_autoload_load() */
{
#if STACK_INSN_CODE
    val = vm_get_ev_const(ec, klass, id, 0);
#endif
}

/* Set constant variable id under cbase class or module.
 */
DEFINE_INSN
setconstant
(ID id)
(VALUE val, VALUE cbase)
()
/* Assigning an object to a constant is basically a leaf operation.
 * The problem is, assigning a Module instance to a constant _names_
 * that module.  Naming involves string manipulations, which are
 * method calls. */
// attr bool leaf = false; /* has StringValue() */
{
#if STACK_INSN_CODE
    vm_check_if_namespace(cbase);
    vm_ensure_not_refinement_module(GET_SELF());
    rb_const_set(cbase, id, val);
#endif
}

/* get global variable id. */
DEFINE_INSN
getglobal
(GENTRY entry)
()
(VALUE val)
// attr bool leaf = leafness_of_getglobal(entry);
{
#if STACK_INSN_CODE
    val = GET_GLOBAL((VALUE)entry);
#endif
}

/* set global variable id as val. */
DEFINE_INSN
setglobal
(GENTRY entry)
(VALUE val)
()
// attr bool leaf = leafness_of_setglobal(entry);
{
#if STACK_INSN_CODE
    SET_GLOBAL((VALUE)entry, val);
#endif
}

/**********************************************************/
/* deal with values                                       */
/**********************************************************/

/* put nil to stack. */
DEFINE_INSN
putnil
()
()
(VALUE val)
{
#if STACK_INSN_CODE
    val = Qnil;
#endif
}

/* put self. */
DEFINE_INSN
putself
()
()
(VALUE val)
{
#if STACK_INSN_CODE
    val = GET_SELF();
#endif
}

/* put some object.
     i.e. Fixnum, true, false, nil, and so on.
 */
DEFINE_INSN
putobject
(VALUE val)
()
(VALUE val)
{
#if STACK_INSN_CODE
    /* */
#endif
}

/* put special object.  "value_type" is for expansion. */
DEFINE_INSN
putspecialobject
(rb_num_t value_type)
()
(VALUE val)
{
#if STACK_INSN_CODE
    enum vm_special_object_type type;

    type = (enum vm_special_object_type)value_type;
    val = vm_get_special_object(GET_EP(), type);
#endif
}

/* put iseq value. */
DEFINE_INSN
putiseq
(ISEQ iseq)
()
(VALUE ret)
// attr bool leaf = true; /* yes it is */
{
#if STACK_INSN_CODE
    ret = (VALUE)iseq;
#endif
}

/* put string val. string will be copied. */
DEFINE_INSN
putstring
(VALUE str)
()
(VALUE val)
{
#if STACK_INSN_CODE
    val = rb_str_resurrect(str);
#endif
}

/* put concatenate strings */
DEFINE_INSN
concatstrings
(rb_num_t num)
(...)
(VALUE val)
// attr rb_snum_t sp_inc = 1 - num;
{
#if STACK_INSN_CODE
    val = rb_str_concat_literals(num, STACK_ADDR_FROM_TOP(num));
#endif
}

/* push the result of to_s. */
DEFINE_INSN
tostring
()
(VALUE val, VALUE str)
(VALUE val)
{
#if STACK_INSN_CODE
    val = rb_obj_as_string_result(str, val);
#endif
}

/* Freeze (dynamically) created strings. if debug_info is given, set it. */
DEFINE_INSN
freezestring
(VALUE debug_info)
(VALUE str)
(VALUE str)
{
#if STACK_INSN_CODE
    vm_freezestring(str, debug_info);
#endif
}

/* compile str to Regexp and push it.
     opt is the option for the Regexp.
 */
DEFINE_INSN
toregexp
(rb_num_t opt, rb_num_t cnt)
(...)
(VALUE val)
/* This instruction has StringValue(), which is a method call.  But it
 * seems that path is never covered. */
// attr bool leaf = true; /* yes it is */
// attr rb_snum_t sp_inc = 1 - cnt;
{
#if STACK_INSN_CODE
    const VALUE ary = rb_ary_tmp_new_from_values(0, cnt, STACK_ADDR_FROM_TOP(cnt));
    val = rb_reg_new_ary(ary, (int)opt);
    rb_ary_clear(ary);
#endif
}

/* intern str to Symbol and push it. */
DEFINE_INSN
intern
()
(VALUE str)
(VALUE sym)
{
    sym = rb_str_intern(str);
}

/* put new array initialized with num values on the stack. */
DEFINE_INSN
newarray
(rb_num_t num)
(...)
(VALUE val)
// attr rb_snum_t sp_inc = 1 - num;
{
#if STACK_INSN_CODE
    val = rb_ary_new4(num, STACK_ADDR_FROM_TOP(num));
#endif
}

/* dup array */
DEFINE_INSN
duparray
(VALUE ary)
()
(VALUE val)
{
#if STACK_INSN_CODE
    val = rb_ary_resurrect(ary);
#endif
}

/* if TOS is an array expand, expand it to num objects.
     if the number of the array is less than num, push nils to fill.
     if it is greater than num, exceeding elements are dropped.
     unless TOS is an array, push num - 1 nils.
     if flags is non-zero, push the array of the rest elements.
     flag: 0x01 - rest args array
     flag: 0x02 - for postarg
     flag: 0x04 - reverse?
 */
DEFINE_INSN
expandarray
(rb_num_t num, rb_num_t flag)
(..., VALUE ary)
(...)
// attr bool leaf = false; /* has rb_check_array_type() */
// attr rb_snum_t sp_inc = num - 1 + (flag & 1 ? 1 : 0);
{
#if STACK_INSN_CODE
    vm_expandarray(GET_SP(), ary, num, (int)flag);
#endif
}

/* concat two arrays */
DEFINE_INSN
concatarray
()
(VALUE ary1, VALUE ary2)
(VALUE ary)
// attr bool leaf = false; /* has rb_check_array_type() */
{
#if STACK_INSN_CODE
    ary = vm_concat_array(ary1, ary2);
#endif
}

/* call to_a on array ary to splat */
DEFINE_INSN
splatarray
(VALUE flag)
(VALUE ary)
(VALUE obj)
// attr bool leaf = false; /* has rb_check_array_type() */
{
#if STACK_INSN_CODE
    obj = vm_splat_array(flag, ary);
#endif
}

/* put new Hash from n elements. n must be an even number. */
DEFINE_INSN
newhash
(rb_num_t num)
(...)
(VALUE val)
// attr bool leaf = false; /* has rb_hash_key_str() */
// attr rb_snum_t sp_inc = 1 - num;
{
#if STACK_INSN_CODE
    RUBY_DTRACE_CREATE_HOOK(HASH, num);

    val = rb_hash_new_with_size(num / 2);

    if (num) {
        rb_hash_bulk_insert(num, STACK_ADDR_FROM_TOP(num), val);
    }
#endif
}

/* put new Range object.(Range.new(low, high, flag)) */
DEFINE_INSN
newrange
(rb_num_t flag)
(VALUE low, VALUE high)
(VALUE val)
/* rb_range_new() exercises "bad value for range" check. */
// attr bool leaf = false; /* see also: range.c:range_init() */
{
#if STACK_INSN_CODE
    val = rb_range_new(low, high, (int)flag);
#endif
}

/**********************************************************/
/* deal with stack operation                              */
/**********************************************************/

/* pop from stack. */
DEFINE_INSN
pop
()
(VALUE val)
()
{
#if STACK_INSN_CODE
    (void)val;
    /* none */
#endif
}

/* duplicate stack top. */
DEFINE_INSN
dup
()
(VALUE val)
(VALUE val1, VALUE val2)
{
#if STACK_INSN_CODE
    val1 = val2 = val;
#endif
}

/* duplicate stack top n elements */
DEFINE_INSN
dupn
(rb_num_t n)
(...)
(...)
// attr rb_snum_t sp_inc = n;
{
#if STACK_INSN_CODE
    void *dst = GET_SP();
    void *src = STACK_ADDR_FROM_TOP(n);

    MEMCPY(dst, src, VALUE, n);
#endif
}

/* swap top 2 vals */
DEFINE_INSN
swap
()
(VALUE val, VALUE obj)
(VALUE obj, VALUE val)
{
#if STACK_INSN_CODE
    /* none */
#endif
}

/* reverse stack top N order. */
DEFINE_INSN
reverse
(rb_num_t n)
(...)
(...)
// attr rb_snum_t sp_inc = 0;
{
#if STACK_INSN_CODE
    rb_num_t i;
    VALUE *sp = STACK_ADDR_FROM_TOP(n);

    for (i=0; i<n/2; i++) {
	VALUE v0 = sp[i];
	VALUE v1 = TOPN(i);
	sp[i] = v1;
	TOPN(i) = v0;
    }
#endif
}

/* for stack caching. */
DEFINE_INSN
reput
()
(..., VALUE val)
(VALUE val)
// attr rb_snum_t sp_inc = 0;
{
    /* none */
}

/* get nth stack value from stack top */
DEFINE_INSN
topn
(rb_num_t n)
(...)
(VALUE val)
// attr rb_snum_t sp_inc = 1;
{
#if STACK_INSN_CODE
    val = TOPN(n);
#endif
}

/* set Nth stack entry to stack top */
DEFINE_INSN
setn
(rb_num_t n)
(..., VALUE val)
(VALUE val)
// attr rb_snum_t sp_inc = 0;
{
#if STACK_INSN_CODE
    TOPN(n) = val;
#endif
}

/* empty current stack */
DEFINE_INSN
adjuststack
(rb_num_t n)
(...)
(...)
// attr rb_snum_t sp_inc = -(rb_snum_t)n;
{
    /* none */
}

/**********************************************************/
/* deal with setting                                      */
/**********************************************************/

/* defined? */
DEFINE_INSN
defined
(rb_num_t op_type, VALUE obj, VALUE needstr)
(VALUE v)
(VALUE val)
// attr bool leaf = leafness_of_defined(op_type);
{
#if STACK_INSN_CODE
    val = vm_defined(ec, GET_CFP(), op_type, obj, needstr, v);
#endif
}

/* check `target' matches `pattern'.
     `flag & VM_CHECKMATCH_TYPE_MASK' describe how to check pattern.
      VM_CHECKMATCH_TYPE_WHEN: ignore target and check pattern is truthy.
      VM_CHECKMATCH_TYPE_CASE: check `patten === target'.
      VM_CHECKMATCH_TYPE_RESCUE: check `pattern.kind_op?(Module) && pattern === target'.
     if `flag & VM_CHECKMATCH_ARRAY' is not 0, then `patten' is array of patterns.
 */
DEFINE_INSN
checkmatch
(rb_num_t flag)
(VALUE target, VALUE pattern)
(VALUE result)
// attr bool leaf = leafness_of_checkmatch(flag);
{
#if STACK_INSN_CODE
    result = vm_check_match(ec, target, pattern, flag);
#endif
}

/* check keywords are specified or not. */
DEFINE_INSN
checkkeyword
(lindex_t kw_bits_index, lindex_t keyword_index)
()
(VALUE ret)
{
#if STACK_INSN_CODE
    ret = vm_check_keyword(kw_bits_index, keyword_index, GET_EP());
#endif
}

/* check if val is type. */
DEFINE_INSN
checktype
(rb_num_t type)
(VALUE val)
(VALUE ret)
{
#if STACK_INSN_CODE
    ret = (TYPE(val) == (int)type) ? Qtrue : Qfalse;
#endif
}

/* fire a coverage event (currently, this is used for line coverage and branch coverage) */
DEFINE_INSN
tracecoverage
(rb_num_t nf, VALUE data)
()
()
{
    rb_event_flag_t flag = (rb_event_flag_t)nf;

    vm_dtrace(flag, ec);
    EXEC_EVENT_HOOK(ec, flag, GET_SELF(), 0, 0, 0 /* id and klass are resolved at callee */, data);
}

/**********************************************************/
/* deal with control flow 1: class/module                 */
/**********************************************************/

/* enter class definition scope. if super is Qfalse, and class
   "klass" is defined, it's redefine. otherwise, define "klass" class.
 */
DEFINE_INSN
defineclass
(ID id, ISEQ class_iseq, rb_num_t flags)
(VALUE cbase, VALUE super)
(VALUE val)
// attr bool handles_sp = true;
{
#if STACK_INSN_CODE
    VALUE klass = vm_find_or_create_class_by_id(id, flags, cbase, super);

    rb_iseq_check(class_iseq);

    /* enter scope */
    vm_push_frame(ec, class_iseq, VM_FRAME_MAGIC_CLASS | VM_ENV_FLAG_LOCAL, klass,
		  GET_BLOCK_HANDLER(),
		  (VALUE)vm_cref_push(ec, klass, NULL, FALSE),
		  class_iseq->body->iseq_encoded, GET_SP(),
		  class_iseq->body->local_table_size,
		  class_iseq->body->stack_max);
    RESTORE_REGS();
    NEXT_INSN();
#endif
}

/**********************************************************/
/* deal with control flow 2: method/iterator              */
/**********************************************************/

/* invoke method. */
DEFINE_INSN
send
(CALL_INFO ci, CALL_CACHE cc, ISEQ blockiseq)
(...)
(VALUE val)
// attr bool handles_sp = true;
// attr rb_snum_t sp_inc = - (int)(ci->orig_argc + ((ci->flag & VM_CALL_ARGS_BLOCKARG) ? 1 : 0));
{
#if STACK_INSN_CODE
    struct rb_calling_info calling;

    calling.block_handler = vm_caller_setup_arg_block(ec, reg_cfp, ci, blockiseq, FALSE);
    calling.recv = TOPN(calling.argc = ci->orig_argc);
    vm_search_method(ci, cc, calling.recv);
    CALL_METHOD(&calling, ci, cc);
#endif
}

/* Invoke method without block */
DEFINE_INSN
opt_send_without_block
(CALL_INFO ci, CALL_CACHE cc)
(...)
(VALUE val)
// attr bool leaf = false; /* Of course it isn't. */
// attr bool handles_sp = true;
// attr rb_snum_t sp_inc = -ci->orig_argc;
{
#if STACK_INSN_CODE
    struct rb_calling_info calling;
    calling.block_handler = VM_BLOCK_HANDLER_NONE;
    vm_search_method(ci, cc, calling.recv = TOPN(calling.argc = ci->orig_argc));
    CALL_METHOD(&calling, ci, cc);
#endif
}

DEFINE_INSN
opt_str_freeze
(VALUE str, CALL_INFO ci, CALL_CACHE cc)
()
(VALUE val)
{
#if STACK_INSN_CODE
    val = vm_opt_str_freeze(str, BOP_FREEZE, idFreeze);

    if (val == Qundef) {
        PUSH(rb_str_resurrect(str));
        CALL_SIMPLE_METHOD();
    }
#endif
}

DEFINE_INSN
opt_str_uminus
(VALUE str, CALL_INFO ci, CALL_CACHE cc)
()
(VALUE val)
{
#if STACK_INSN_CODE
    val = vm_opt_str_freeze(str, BOP_UMINUS, idUMinus);

    if (val == Qundef) {
        PUSH(rb_str_resurrect(str));
        CALL_SIMPLE_METHOD();
    }
#endif
}

DEFINE_INSN
opt_newarray_max
(rb_num_t num)
(...)
(VALUE val)
/* This instruction typically has no funcalls.  But it compares array
 * contents each other by nature.  That part could call methods when
 * necessary.  No way to detect such method calls beforehand.  We
 * cannot but mark it being not leaf. */
// attr bool leaf = false; /* has rb_funcall() */
// attr rb_snum_t sp_inc = 1 - num;
{
    val = vm_opt_newarray_max(num, STACK_ADDR_FROM_TOP(num));
}

DEFINE_INSN
opt_newarray_min
(rb_num_t num)
(...)
(VALUE val)
/* Same discussion as opt_newarray_max. */
// attr bool leaf = false; /* has rb_funcall() */
// attr rb_snum_t sp_inc = 1 - num;
{
#if STACK_INSN_CODE
    val = vm_opt_newarray_min(num, STACK_ADDR_FROM_TOP(num));
#endif
}

/* super(args) # args.size => num */
DEFINE_INSN
invokesuper
(CALL_INFO ci, CALL_CACHE cc, ISEQ blockiseq)
(...)
(VALUE val)
// attr bool handles_sp = true;
// attr rb_snum_t sp_inc = - (int)(ci->orig_argc + ((ci->flag & VM_CALL_ARGS_BLOCKARG) ? 1 : 0));
{
#if STACK_INSN_CODE
    struct rb_calling_info calling;

    calling.block_handler = vm_caller_setup_arg_block(ec, reg_cfp, ci, blockiseq, TRUE);
    calling.recv = TOPN(calling.argc = ci->orig_argc);
    vm_search_super_method(ec, GET_CFP(), &calling, ci, cc);
    CALL_METHOD(&calling, ci, cc);
#endif
}

/* yield(args) */
DEFINE_INSN
invokeblock
(CALL_INFO ci)
(...)
(VALUE val)
// attr bool leaf = false; /* Of course it isn't. */
// attr bool handles_sp = true;
// attr rb_snum_t sp_inc = 1 - ci->orig_argc;
{
#if STACK_INSN_CODE
    struct rb_calling_info calling;
    VALUE block_handler;

    calling.argc = ci->orig_argc;
    calling.block_handler = VM_BLOCK_HANDLER_NONE;
    calling.recv = Qundef; /* should not be used */

    block_handler = VM_CF_BLOCK_HANDLER(GET_CFP());
    if (block_handler == VM_BLOCK_HANDLER_NONE) {
	rb_vm_localjump_error("no block given (yield)", Qnil, 0);
    }

    val = vm_invoke_block(ec, GET_CFP(), &calling, ci, block_handler);
    if (val == Qundef) {
        EXEC_EC_CFP(val);
    }
#endif
}

/* return from this scope. */
DEFINE_INSN
leave
()
(VALUE val)
(VALUE val)
/* This is super surprising but when leaving from a frame, we check
 * for interrupts.  If any, that should be executed on top of the
 * current execution context.  This is a method call. */
// attr bool leaf = false; /* has rb_threadptr_execute_interrupts() */
// attr bool handles_sp = true;
{
#if STACK_INSN_CODE
    if (OPT_CHECKED_RUN) {
	const VALUE *const bp = vm_base_ptr(reg_cfp);
	if (reg_cfp->sp != bp) {
	    vm_stack_consistency_error(ec, reg_cfp, bp);
	}
    }

    RUBY_VM_CHECK_INTS(ec);

    if (vm_pop_frame(ec, GET_CFP(), GET_EP())) {
#if OPT_CALL_THREADED_CODE
	rb_ec_thread_ptr(ec)->retval = val;
	return 0;
#else
	return val;
#endif
    }
    else {
	RESTORE_REGS();
    }
#endif
}

/**********************************************************/
/* deal with control flow 3: exception                    */
/**********************************************************/

/* longjump */
DEFINE_INSN
throw
(rb_num_t throw_state)
(VALUE throwobj)
(VALUE val)
/* Same discussion as leave. */
// attr bool leaf = false; /* has rb_threadptr_execute_interrupts() */
{
#if STACK_INSN_CODE
    RUBY_VM_CHECK_INTS(ec);
    val = vm_throw(ec, GET_CFP(), throw_state, throwobj);
    THROW_EXCEPTION(val);
    /* unreachable */
#endif
}

/**********************************************************/
/* deal with control flow 4: local jump                   */
/**********************************************************/

/* set PC to (PC + dst). */
DEFINE_INSN
jump
(OFFSET dst)
()
()
/* Same discussion as leave. */
// attr bool leaf = false; /* has rb_threadptr_execute_interrupts() */
{
#if STACK_INSN_CODE
    RUBY_VM_CHECK_INTS(ec);
    JUMP(dst);
#endif
}

/* if val is not false or nil, set PC to (PC + dst). */
DEFINE_INSN
branchif
(OFFSET dst)
(VALUE val)
()
/* Same discussion as jump. */
// attr bool leaf = false; /* has rb_threadptr_execute_interrupts() */
{
#if STACK_INSN_CODE
    if (RTEST(val)) {
	RUBY_VM_CHECK_INTS(ec);
	JUMP(dst);
    }
#endif
}

/* if val is false or nil, set PC to (PC + dst). */
DEFINE_INSN
branchunless
(OFFSET dst)
(VALUE val)
()
/* Same discussion as jump. */
// attr bool leaf = false; /* has rb_threadptr_execute_interrupts() */
{
#if STACK_INSN_CODE
    if (!RTEST(val)) {
	RUBY_VM_CHECK_INTS(ec);
	JUMP(dst);
    }
#endif
}

/* if val is nil, set PC to (PC + dst). */
DEFINE_INSN
branchnil
(OFFSET dst)
(VALUE val)
()
/* Same discussion as jump. */
// attr bool leaf = false; /* has rb_threadptr_execute_interrupts() */
{
#if STACK_INSN_CODE
    if (NIL_P(val)) {
	RUBY_VM_CHECK_INTS(ec);
	JUMP(dst);
    }
#endif
}

/**********************************************************/
/* for optimize                                           */
/**********************************************************/

/* push inline-cached value and go to dst if it is valid */
DEFINE_INSN
getinlinecache
(OFFSET dst, IC ic)
()
(VALUE val)
{
#if STACK_INSN_CODE
    if (vm_ic_hit_p(ic, GET_EP())) {
	val = ic->ic_value.value;
	JUMP(dst);
    }
    else {
	val = Qnil;
    }
#endif
}

/* set inline cache */
DEFINE_INSN
setinlinecache
(IC ic)
(VALUE val)
(VALUE val)
{
#if STACK_INSN_CODE
    vm_ic_update(ic, val, GET_EP());
#endif
}

/* run iseq only once */
DEFINE_INSN
once
(ISEQ iseq, ISE ise)
()
(VALUE val)
{
#if STACK_INSN_CODE
    val = vm_once_dispatch(ec, iseq, ise);
#endif
}

/* case dispatcher, jump by table if possible */
DEFINE_INSN
opt_case_dispatch
(CDHASH hash, OFFSET else_offset)
(..., VALUE key)
()
// attr rb_snum_t sp_inc = -1;
{
#if STACK_INSN_CODE
    OFFSET dst = vm_case_dispatch(hash, else_offset, key);

    if (dst) {
	JUMP(dst);
    }
#endif
}

/** simple functions */

/* optimized X+Y. */
DEFINE_INSN
opt_plus
(CALL_INFO ci, CALL_CACHE cc)
(VALUE recv, VALUE obj)
(VALUE val)
/* Array + anything can be handled inside of opt_plus, and that
 * anything is converted into array using #to_ary. */
// attr bool leaf = false; /* has rb_to_array_type() */
{
#if STACK_INSN_CODE
    val = vm_opt_plus(recv, obj);

    if (val == Qundef) {
        CALL_SIMPLE_METHOD();
    }
#endif
}

/* optimized X-Y. */
DEFINE_INSN
opt_minus
(CALL_INFO ci, CALL_CACHE cc)
(VALUE recv, VALUE obj)
(VALUE val)
{
#if STACK_INSN_CODE
    val = vm_opt_minus(recv, obj);

    if (val == Qundef) {
        CALL_SIMPLE_METHOD();
    }
#endif
}

/* optimized X*Y. */
DEFINE_INSN
opt_mult
(CALL_INFO ci, CALL_CACHE cc)
(VALUE recv, VALUE obj)
(VALUE val)
{
#if STACK_INSN_CODE
    val = vm_opt_mult(recv, obj);

    if (val == Qundef) {
        CALL_SIMPLE_METHOD();
    }
#endif
}

/* optimized X/Y. */
DEFINE_INSN
opt_div
(CALL_INFO ci, CALL_CACHE cc)
(VALUE recv, VALUE obj)
(VALUE val)
{
#if STACK_INSN_CODE
    val = vm_opt_div(recv, obj);

    if (val == Qundef) {
        CALL_SIMPLE_METHOD();
    }
#endif
}

/* optimized X%Y. */
DEFINE_INSN
opt_mod
(CALL_INFO ci, CALL_CACHE cc)
(VALUE recv, VALUE obj)
(VALUE val)
{
#if STACK_INSN_CODE
    val = vm_opt_mod(recv, obj);

    if (val == Qundef) {
        CALL_SIMPLE_METHOD();
    }
#endif
}

/* optimized X==Y. */
DEFINE_INSN
opt_eq
(CALL_INFO ci, CALL_CACHE cc)
(VALUE recv, VALUE obj)
(VALUE val)
/* This instruction can compare a string with non-string.  This
 * (somewhat) coerces the non-string into a string, via a method
 * call. */
// attr bool leaf = false; /* has rb_str_equal() */
{
#if STACK_INSN_CODE
    val = opt_eq_func(recv, obj, ci, cc);

    if (val == Qundef) {
        CALL_SIMPLE_METHOD();
    }
#endif
}

/* optimized X!=Y. */
DEFINE_INSN
opt_neq
(CALL_INFO ci_eq, CALL_CACHE cc_eq, CALL_INFO ci, CALL_CACHE cc)
(VALUE recv, VALUE obj)
(VALUE val)
/* Same discussion as opt_eq. */
// attr bool leaf = false; /* has rb_str_equal() */
{
#if STACK_INSN_CODE
    val = vm_opt_neq(ci, cc, ci_eq, cc_eq, recv, obj);

    if (val == Qundef) {
        CALL_SIMPLE_METHOD();
    }
#endif
}

/* optimized X<Y. */
DEFINE_INSN
opt_lt
(CALL_INFO ci, CALL_CACHE cc)
(VALUE recv, VALUE obj)
(VALUE val)
{
#if STACK_INSN_CODE
    val = vm_opt_lt(recv, obj);

    if (val == Qundef) {
        CALL_SIMPLE_METHOD();
    }
#endif
}

/* optimized X<=Y. */
DEFINE_INSN
opt_le
(CALL_INFO ci, CALL_CACHE cc)
(VALUE recv, VALUE obj)
(VALUE val)
{
#if STACK_INSN_CODE
    val = vm_opt_le(recv, obj);

    if (val == Qundef) {
        CALL_SIMPLE_METHOD();
    }
#endif
}

/* optimized X>Y. */
DEFINE_INSN
opt_gt
(CALL_INFO ci, CALL_CACHE cc)
(VALUE recv, VALUE obj)
(VALUE val)
{
#if STACK_INSN_CODE
    val = vm_opt_gt(recv, obj);

    if (val == Qundef) {
        CALL_SIMPLE_METHOD();
    }
#endif
}

/* optimized X>=Y. */
DEFINE_INSN
opt_ge
(CALL_INFO ci, CALL_CACHE cc)
(VALUE recv, VALUE obj)
(VALUE val)
{
#if STACK_INSN_CODE
    val = vm_opt_ge(recv, obj);

    if (val == Qundef) {
        CALL_SIMPLE_METHOD();
    }
#endif
}

/* << */
DEFINE_INSN
opt_ltlt
(CALL_INFO ci, CALL_CACHE cc)
(VALUE recv, VALUE obj)
(VALUE val)
{
#if STACK_INSN_CODE
    val = vm_opt_ltlt(recv, obj);

    if (val == Qundef) {
        CALL_SIMPLE_METHOD();
    }
#endif
}

/* optimized X&Y. */
DEFINE_INSN
opt_and
(CALL_INFO ci, CALL_CACHE cc)
(VALUE recv, VALUE obj)
(VALUE val)
{
#if STACK_INSN_CODE
    val = vm_opt_and(recv, obj);

    if (val == Qundef) {
        CALL_SIMPLE_METHOD();
    }
#endif
}

/* optimized X|Y. */
DEFINE_INSN
opt_or
(CALL_INFO ci, CALL_CACHE cc)
(VALUE recv, VALUE obj)
(VALUE val)
{
#if STACK_INSN_CODE
    val = vm_opt_or(recv, obj);

    if (val == Qundef) {
        CALL_SIMPLE_METHOD();
    }
#endif
}

/* [] */
DEFINE_INSN
opt_aref
(CALL_INFO ci, CALL_CACHE cc)
(VALUE recv, VALUE obj)
(VALUE val)
/* This is complicated.  In case of hash, vm_opt_aref() resorts to
 * rb_hash_aref().  If `recv` has no `obj`, this function then yields
 * default_proc.  This is a method call.  So opt_aref is
 * (surprisingly) not leaf. */
// attr bool leaf = false; /* has rb_funcall() */ /* calls #yield */
{
#if STACK_INSN_CODE
    val = vm_opt_aref(recv, obj);

    if (val == Qundef) {
        CALL_SIMPLE_METHOD();
    }
#endif
}

/* recv[obj] = set */
DEFINE_INSN
opt_aset
(CALL_INFO ci, CALL_CACHE cc)
(VALUE recv, VALUE obj, VALUE set)
(VALUE val)
/* This is another story than opt_aref.  When vm_opt_aset() resorts
 * to rb_hash_aset(), which should call #hash for `obj`. */
// attr bool leaf = false; /* has rb_funcall() */ /* calls #hash */
{
#if STACK_INSN_CODE
    val = vm_opt_aset(recv, obj, set);

    if (val == Qundef) {
        CALL_SIMPLE_METHOD();
    }
#endif
}

/* recv[str] = set */
DEFINE_INSN
opt_aset_with
(VALUE key, CALL_INFO ci, CALL_CACHE cc)
(VALUE recv, VALUE val)
(VALUE val)
/* Same discussion as opt_aset. */
// attr bool leaf = false; /* has rb_funcall() */ /* calls #hash */
{
#if STACK_INSN_CODE
    VALUE tmp = vm_opt_aset_with(recv, key, val);

    if (tmp != Qundef) {
	val = tmp;
    }
    else {
#ifndef MJIT_HEADER
	TOPN(0) = rb_str_resurrect(key);
	PUSH(val);
#endif
        CALL_SIMPLE_METHOD();
    }
#endif
}

/* recv[str] */
DEFINE_INSN
opt_aref_with
(VALUE key, CALL_INFO ci, CALL_CACHE cc)
(VALUE recv)
(VALUE val)
/* Same discussion as opt_aref. */
// attr bool leaf = false; /* has rb_funcall() */ /* calls #yield */
{
#if STACK_INSN_CODE
    val = vm_opt_aref_with(recv, key);

    if (val == Qundef) {
#ifndef MJIT_HEADER
	PUSH(rb_str_resurrect(key));
#endif
        CALL_SIMPLE_METHOD();
    }
#endif
}

/* optimized length */
DEFINE_INSN
opt_length
(CALL_INFO ci, CALL_CACHE cc)
(VALUE recv)
(VALUE val)
{
#if STACK_INSN_CODE
    val = vm_opt_length(recv, BOP_LENGTH);

    if (val == Qundef) {
        CALL_SIMPLE_METHOD();
    }
#endif
}

/* optimized size */
DEFINE_INSN
opt_size
(CALL_INFO ci, CALL_CACHE cc)
(VALUE recv)
(VALUE val)
{
#if STACK_INSN_CODE
    val = vm_opt_length(recv, BOP_SIZE);

    if (val == Qundef) {
        CALL_SIMPLE_METHOD();
    }
#endif
}

/* optimized empty? */
DEFINE_INSN
opt_empty_p
(CALL_INFO ci, CALL_CACHE cc)
(VALUE recv)
(VALUE val)
{
#if STACK_INSN_CODE
    val = vm_opt_empty_p(recv);

    if (val == Qundef) {
        CALL_SIMPLE_METHOD();
    }
#endif
}

/* optimized succ */
DEFINE_INSN
opt_succ
(CALL_INFO ci, CALL_CACHE cc)
(VALUE recv)
(VALUE val)
{
#if STACK_INSN_CODE
    val = vm_opt_succ(recv);

    if (val == Qundef) {
        CALL_SIMPLE_METHOD();
    }
#endif
}

/* optimized not */
DEFINE_INSN
opt_not
(CALL_INFO ci, CALL_CACHE cc)
(VALUE recv)
(VALUE val)
{
#if STACK_INSN_CODE
    val = vm_opt_not(ci, cc, recv);

    if (val == Qundef) {
        CALL_SIMPLE_METHOD();
    }
#endif
}

/* optimized regexp match */
DEFINE_INSN
opt_regexpmatch1
(VALUE recv)
(VALUE obj)
(VALUE val)
// attr bool leaf = BASIC_OP_UNREDEFINED_P(BOP_MATCH, REGEXP_REDEFINED_OP_FLAG);
{
#if STACK_INSN_CODE
    val = vm_opt_regexpmatch1(recv, obj);
#endif
}

/* optimized regexp match 2 */
DEFINE_INSN
opt_regexpmatch2
(CALL_INFO ci, CALL_CACHE cc)
(VALUE obj2, VALUE obj1)
(VALUE val)
{
#if STACK_INSN_CODE
    val = vm_opt_regexpmatch2(obj2, obj1);

    if (val == Qundef) {
        CALL_SIMPLE_METHOD();
    }
#endif
}

/* call native compiled method */
DEFINE_INSN
opt_call_c_function
(rb_insn_func_t funcptr)
()
()
// attr bool leaf = false; /* anything can happen inside */
// attr bool handles_sp = true;
{
#if STACK_INSN_CODE
    reg_cfp = (funcptr)(ec, reg_cfp);

    if (reg_cfp == 0) {
	VALUE err = ec->errinfo;
	ec->errinfo = Qnil;
	THROW_EXCEPTION(err);
    }

    RESTORE_REGS();
    NEXT_INSN();
#endif
}

/* BLT */
DEFINE_INSN
bitblt
()
()
(VALUE ret)
{
#if STACK_INSN_CODE
    ret = rb_str_new2("a bit of bacon, lettuce and tomato");
#endif
}

/* The Answer to Life, the Universe, and Everything */
DEFINE_INSN
answer
()
()
(VALUE ret)
{
#if STACK_INSN_CODE
    ret = INT2FIX(42);
#endif
}

/*------------------- Common RTL and stack insns: ------------*/

/* nop */
DEFINE_INSN
nop
()
()
()
{
    nop_f(reg_cfp);
}

/*------------------------ RTL insns: ------------------------*/

/* The file describes RTL (Register Transfer Language) insns.  We keep
   minimal code here.  The RTL insn semantics are actually implemented
   in file rtl_exec.c.  Please, read comments there to understand what
   the insns do.

   Code for most insns here is just a call of the corresponding
   function.  There is a strict correspondence between the insn name
   and the corresponding function name and between insn operands and
   their types and the function arguments and their types.  It is done
   to simplify JIT compilation by mostly translating each RTL insn
   into the corresponding function call in the JIT generated code.


   Some abbreviations in the insn names:

   temp   - a temporary variable in the current stack frame.  It is
            addressed by negative integers
   loc    - a Ruby local variable (environemnt variable in MRI terms)
            of the current scope.  It is addressed by positive integers
   var    - temp or local
   uploc  - a Ruby local variable from an upper level
   ivar   - a Ruby instance variable
   cvar   - a Ruby class variable
   global - a Ruby global variable

   Some prefixes in the insn names:
     u - an unchanging general insn.  Some general insns can be
         transformed into speculative ones and after that into the
         unchanging insns if the speculation was wrong
     i - a speculative insn assuming integer operands
     f - a speculative insn assuming floating point operands

   Some insn operand types:

     vindex_t - offset on the stack or in the environment.  Positive
                value means local var, negative value means a
                temporary var.  The function implementing the insn get
                the address of the local or temporary operand as an
                argument
     tindex_t - a negative offset on the stack. The function
                implementing the insn get the address of the temporary
                operand as an argument
     rindex_t - the same as above but the offset is passed to besides
                the address
     sindex_t - a negative number which offset of the temporary on the
                stack. Only the number itself is passed as an argument

  instruction format:
    DEFINE_INSN
    instruction_name ..
    (instruction_operands, ..)
    (pop_values, ..)
    (return value)
    {
       .. // insn body
    }

    DEFINE_INSN can define more one similar insns.  Macro
    NAME_OF_CURRENT_INSN is defined in the body and contains the name of
    the currently executed insn.

    Instruction operand can be underscore "_" or "<type> _".  It means
    we ignore the operand completely for execution of this insn in the
    interpreter.  Just underscore also means don't pass the operand in
    JIT generated code to a function executing the insn.

    TODO: Remove pop_values and the return value as RTL insns never
    use them.
*/


DEFINE_INSN
var2var
(rindex_t to, vindex_t from, rb_num_t n)
()
()
{
    var2var_f(reg_cfp, get_var_addr(reg_cfp, to), to, get_var_addr(reg_cfp, from), n);
}

DEFINE_INSN
var_swap
(rindex_t op1, rindex_t op2)
()
()
{
    var_swap_f(reg_cfp, get_var_addr(reg_cfp, op1), op1, get_var_addr(reg_cfp, op2), op2);
}

DEFINE_INSN
temp2temp
(tindex_t res, tindex_t op)
()
()
{
    temp2temp_f(reg_cfp, get_temp_addr(reg_cfp, res), get_temp_addr(reg_cfp, op));
}

DEFINE_INSN
temp_swap
(tindex_t op1, tindex_t op2)
()
()
{
    temp_swap_f(reg_cfp, get_temp_addr(reg_cfp, op1), get_temp_addr(reg_cfp, op2));
}

DEFINE_INSN
temp_reverse
(rb_num_t n, tindex_t start)
()
()
{
    temp_reverse_f(reg_cfp, n, get_temp_addr(reg_cfp, start));
}

DEFINE_INSN
loc2loc
(rindex_t res, vindex_t op)
()
()
{
    loc2loc_f(reg_cfp, get_loc_addr(reg_cfp, res), res, get_loc_addr(reg_cfp, op));
}

DEFINE_INSN
loc2temp
(tindex_t res, vindex_t op)
()
()
{
    loc2temp_f(reg_cfp, get_temp_addr(reg_cfp, res), get_loc_addr(reg_cfp, op));
}

DEFINE_INSN
temp2loc
(rindex_t res, tindex_t op)
()
()
{
    temp2loc_f(reg_cfp, get_loc_addr(reg_cfp, res), res, get_temp_addr(reg_cfp, op));
}

DEFINE_INSN
uploc2temp
(vindex_t res, sindex_t op, rb_num_t level)
()
()
{
    uploc2temp_f(reg_cfp, get_var_addr(reg_cfp, res), op, level);
}

DEFINE_INSN
uploc2var
(rindex_t res, sindex_t op, rb_num_t level)
()
()
{
    uploc2var_f(reg_cfp, get_var_addr(reg_cfp, res), res, op, level);
}

DEFINE_INSN
val2loc
(rindex_t res, VALUE val)
()
()
{
    val2loc_f(reg_cfp, get_loc_addr(reg_cfp, res), res, val);
}

DEFINE_INSN
val2temp
(tindex_t res, VALUE val)
()
()
{
    val2temp_f(reg_cfp, get_temp_addr(reg_cfp, res), val);
}

DEFINE_INSN
str2var
(rindex_t res, VALUE str)
()
()
{
    str2var_f(reg_cfp, get_var_addr(reg_cfp, res), res, str);
}

DEFINE_INSN
const2var
(ID id, tindex_t res, vindex_t klass_op)
()
()
// attr bool leaf = false; /* has rb_autoload_load() */
{
    const2var_f(ec, reg_cfp, id, get_temp_addr(reg_cfp, res), get_var_addr(reg_cfp, klass_op));
}

DEFINE_INSN
const_ld_val
(ID id, tindex_t res, VALUE klass)
()
()
// attr bool leaf = false; /* has rb_autoload_load() */
{
    const_ld_val_f(ec, reg_cfp, id, get_temp_addr(reg_cfp, res), klass);
}

/* Increase PC first for correct exception processing.  */
DEFINE_INSN
const_cached_val_ld
(tindex_t res, VALUE klass, ID id, IC ic)
()
()
// attr bool handles_sp = true;
// attr bool leaf = false; /* has rb_autoload_load() */
{
    const_cached_val_ld_f(ec, reg_cfp, get_temp_addr(reg_cfp, res), klass, id, ic);
}

DEFINE_INSN
get_inline_cache
(OFFSET dst, tindex_t res, IC ic)
()
()
{
    if (get_inline_cache_f(reg_cfp, get_temp_addr(reg_cfp, res), ic))
	JUMP(dst);
}

DEFINE_INSN
set_inline_cache
(vindex_t op, IC ic)
()
()
{
    set_inline_cache_f(reg_cfp, get_var_addr(reg_cfp, op), ic);
}

DEFINE_INSN
specialobj2var
(tindex_t res, rb_num_t value_type)
()
()
{
    specialobj2var_f(reg_cfp, get_temp_addr(reg_cfp, res), value_type);
}

DEFINE_INSN
special2var
(tindex_t res, rb_num_t key, rb_num_t type)
()
()
{
    special2var_f(ec, reg_cfp, get_temp_addr(reg_cfp, res), key, type);
}

DEFINE_INSN
self2var
(rindex_t res)
()
()
{
    self2var_f(reg_cfp, get_var_addr(reg_cfp, res), res);
}

DEFINE_INSN
global2var
(tindex_t res, GENTRY entry)
()
()
// attr bool leaf = leafness_of_getglobal(entry);
{
    global2var_f(reg_cfp, get_temp_addr(reg_cfp, res), entry);
}

DEFINE_INSN
ivar2var
(tindex_t res, ID id, IC ic)
()
()
// attr bool leaf = false; /* has rb_warning() */
{
    ivar2var_f(reg_cfp, get_temp_addr(reg_cfp, res), id, ic);
}

DEFINE_INSN
cvar2var
(tindex_t res, ID id)
()
()
// attr bool leaf = false; /* has rb_warning() */
{
    cvar2var_f(reg_cfp, get_temp_addr(reg_cfp, res), id);
}

DEFINE_INSN
iseq2var
(tindex_t res, ISEQ iseq)
()
()
// attr bool leaf = true; /* yes it is */
{
    iseq2var_f(reg_cfp, get_temp_addr(reg_cfp, res), iseq);
}

DEFINE_INSN
var2uploc
(sindex_t idx, vindex_t from, rb_num_t level)
()
()
{
    var2uploc_f(reg_cfp, idx, get_var_addr(reg_cfp, from), level);
}

DEFINE_INSN
val2uploc
(sindex_t idx, VALUE val, rb_num_t level)
()
()
{
    val2uploc_f(reg_cfp, idx, val, level);
}

/* Get a block parameter. */
DEFINE_INSN
get_block_param
(tindex_t res, sindex_t idx, rb_num_t level)
()
()
{
    get_block_param_f(ec, reg_cfp, get_temp_addr(reg_cfp, res), idx, level);
}

/* Set block parameter. */
DEFINE_INSN
set_block_param
(sindex_t idx, rb_num_t level, vindex_t op)
()
()
{
    set_block_param_f(reg_cfp, idx, level, get_var_addr(reg_cfp, op));
}

/* Get special proxy object which only responds to `call` method if the block parameter
     represents a iseq/ifunc block. Otherwise, same as `getblockparam`.
 */
DEFINE_INSN
get_block_param_proxy
(tindex_t res, sindex_t idx, rb_num_t level)
()
()
{
    get_block_param_proxy_f(reg_cfp, get_temp_addr(reg_cfp, res), idx, level);
}

/* Not used anymore: 
DEFINE_INSN
ret_to_loc
(sindex_t idx, vindex_t from)
()
()
// attr bool handles_sp = true;
{
    ret_to_loc_f(ec, reg_cfp, idx, get_var_addr(reg_cfp, from));
    RESTORE_REGS();
    set_default_sp(reg_cfp, reg_cfp->bp);
}

DEFINE_INSN
ret_to_temp
(sindex_t idx, vindex_t from)
()
()
// attr bool handles_sp = true;
{
    ret_to_temp_f(ec, reg_cfp, idx, get_var_addr(reg_cfp, from));
    RESTORE_REGS();
    set_default_sp(reg_cfp, reg_cfp->bp);
}
*/

DEFINE_INSN
var2const
(ID id, vindex_t val_op, vindex_t cbase_op)
()
()
// attr bool leaf = false; /* has StringValue() */
{
    var2const_f(reg_cfp, id, get_var_addr(reg_cfp, val_op), get_var_addr(reg_cfp, cbase_op));
}

DEFINE_INSN
var2global
(GENTRY entry, vindex_t val_op)
()
()
// attr bool leaf = leafness_of_setglobal(entry);
{
    var2global_f(reg_cfp, entry, get_var_addr(reg_cfp, val_op));
}

DEFINE_INSN
temp2ivar
(ID id, IC ic, tindex_t val_op)
()
()
{
    temp2ivar_f(reg_cfp, id, ic, get_temp_addr(reg_cfp, val_op));
}

DEFINE_INSN
loc2ivar
(ID id, IC ic, vindex_t val_op)
()
()
{
    loc2ivar_f(reg_cfp, id, ic, get_loc_addr(reg_cfp, val_op));
}

DEFINE_INSN
val2ivar
(ID id, IC ic, VALUE val)
()
()
{
    val2ivar_f(reg_cfp, id, ic, val);
}

DEFINE_INSN
var2cvar
(ID id, vindex_t val_op)
()
()
// attr bool leaf = false; /* has rb_warning() */
{
    var2cvar_f(reg_cfp, id, get_var_addr(reg_cfp, val_op));
}

DEFINE_INSN
var2special
(rb_num_t key, vindex_t op)
()
()
{
    var2special_f(ec, reg_cfp, key, get_var_addr(reg_cfp, op));
}

DEFINE_INSN
length size empty_p succ not unot
(CALL_DATA cd, tindex_t res, vindex_t op)
()
()
{
    if (RTL_FUNC_NAME(NAME_OF_CURRENT_INSN)(ec, reg_cfp, cd, get_temp_addr(reg_cfp, res), get_var_addr(reg_cfp, op))) {
	ec->cfp[1].pc += 4;
	RESTORE_REGS();
	set_default_sp(reg_cfp, reg_cfp->bp);
	NEXT_INSN();
    }
}

DEFINE_INSN
str2sym
(tindex_t res, vindex_t op)
()
()
{
    str2sym_f(reg_cfp, get_temp_addr(reg_cfp, res), get_var_addr(reg_cfp, op));
}

/* Speculative not insn:  */
DEFINE_INSN
spec_not
(CALL_DATA cd, tindex_t res, vindex_t op)
()
()
{
    enum ruby_vminsn_type new_insn;
    
    if (spec_not_f(reg_cfp, cd, get_temp_addr(reg_cfp, res), get_var_addr(reg_cfp, op), &new_insn)) {
	/* Speculation was wrong.  Change and re-execute the insn.  */
	vm_change_insn(reg_cfp->iseq, GET_PC(), new_insn);
	ADD_PC(-4);
    }
}

/* General and unchanging insns:  */
DEFINE_INSN
plus minus mult div mod or and eq ne ltlt lt gt le ge ind uplus uminus umult udiv umod uor uand ueq une ult ugt ule uge uind
(CALL_DATA cd, tindex_t res, vindex_t op1, vindex_t op2)
()
()
{
    if (RTL_FUNC_NAME(NAME_OF_CURRENT_INSN)(ec, reg_cfp, cd, get_temp_addr(reg_cfp, res), get_var_addr(reg_cfp, op1), get_var_addr(reg_cfp, op2))) {
	ec->cfp[1].pc += 5;
	RESTORE_REGS();
	set_default_sp(reg_cfp, reg_cfp->bp);
	NEXT_INSN();
    }
}

/* General and unchanging simple (stack) insns:  */
DEFINE_INSN
splus sminus smult sdiv smod sor sand seq sne slt sgt sle sge suplus suminus sumult sudiv sumod suor suand sueq sune sult sugt sule suge
(CALL_DATA cd, tindex_t res)
()
()
{
    VALUE *res_op = get_temp_addr(reg_cfp, res);
    
    if (RTL_FUNC_NAME(NAME_OF_CURRENT_INSN)(ec, reg_cfp, cd, res_op, res_op, res_op + 1)) {
	ec->cfp[1].pc += 3;
	RESTORE_REGS();
	set_default_sp(reg_cfp, reg_cfp->bp);
	NEXT_INSN();
    }
}

/* Speculative insns:  */
DEFINE_INSN
fplus fminus fmult fdiv fmod
(CALL_DATA _, tindex_t res, vindex_t op1, vindex_t op2)
()
()
{
    enum ruby_vminsn_type new_insn;
    
    if (RTL_FUNC_NAME(NAME_OF_CURRENT_INSN)(reg_cfp, get_temp_addr(reg_cfp, res),
					    get_var_addr(reg_cfp, op1), get_var_addr(reg_cfp, op2), &new_insn, NULL, NULL, NULL)) {
	/* Speculation was wrong.  Change and re-execute the insn.  */
	vm_change_insn(reg_cfp->iseq, GET_PC(), new_insn);
	ADD_PC(-5);
    }
}

DEFINE_INSN
feq fne flt fgt fle fge
(CALL_DATA _, tindex_t res, vindex_t op1, vindex_t op2)
()
()
{
    enum ruby_vminsn_type new_insn;
    
    if (RTL_FUNC_NAME(NAME_OF_CURRENT_INSN)(reg_cfp, get_temp_addr(reg_cfp, res),
					    get_var_addr(reg_cfp, op1), get_var_addr(reg_cfp, op2), &new_insn, NULL, NULL)) {
	/* Speculation was wrong.  Change and re-execute the insn.  */
	vm_change_insn(reg_cfp->iseq, GET_PC(), new_insn);
	ADD_PC(-5);
    }
}

DEFINE_INSN
iplus iminus imult idiv imod ior iand aind hind ieq ine ilt igt ile ige
(CALL_DATA _, tindex_t res, vindex_t op1, vindex_t op2)
()
()
{
    enum ruby_vminsn_type new_insn;
    
    if (RTL_FUNC_NAME(NAME_OF_CURRENT_INSN)(reg_cfp, get_temp_addr(reg_cfp, res),
					    get_var_addr(reg_cfp, op1), get_var_addr(reg_cfp, op2), &new_insn)) {
	/* Speculation was wrong.  Change and re-execute the insn.  */
	vm_change_insn(reg_cfp->iseq, GET_PC(), new_insn);
	ADD_PC(-5);
    }
}

/* Speculative simple (stack) insns:  */
DEFINE_INSN
sfplus sfminus sfmult sfdiv sfmod
(CALL_DATA _, tindex_t res)
()
()
{
    enum ruby_vminsn_type new_insn;
    VALUE *res_op = get_temp_addr(reg_cfp, res);
    
    if (RTL_FUNC_NAME(NAME_OF_CURRENT_INSN)(reg_cfp, res_op, res_op, res_op + 1, &new_insn, NULL, NULL, NULL)) {
	/* Speculation was wrong.  Change and re-execute the insn.  */
	vm_change_insn(reg_cfp->iseq, GET_PC(), new_insn);
	ADD_PC(-3);
    }
}

DEFINE_INSN
sfeq sfne sflt sfgt sfle sfge
(CALL_DATA _, tindex_t res)
()
()
{
    enum ruby_vminsn_type new_insn;
    VALUE *res_op = get_temp_addr(reg_cfp, res);
    
    if (RTL_FUNC_NAME(NAME_OF_CURRENT_INSN)(reg_cfp, res_op, res_op, res_op + 1, &new_insn, NULL, NULL)) {
	/* Speculation was wrong.  Change and re-execute the insn.  */
	vm_change_insn(reg_cfp->iseq, GET_PC(), new_insn);
	ADD_PC(-3);
    }
}

DEFINE_INSN
siplus siminus simult sidiv simod sior siand sieq sine silt sigt sile sige
(CALL_DATA _, tindex_t res)
()
()
{
    enum ruby_vminsn_type new_insn;
    VALUE *res_op = get_temp_addr(reg_cfp, res);
    
    if (RTL_FUNC_NAME(NAME_OF_CURRENT_INSN)(reg_cfp, res_op, res_op, res_op + 1, &new_insn)) {
	/* Speculation was wrong.  Change and re-execute the insn.  */
	vm_change_insn(reg_cfp->iseq, GET_PC(), new_insn);
	ADD_PC(-3);
    }
}

/* General immediate insns:  */
DEFINE_INSN
plusi minusi plusf minusf multi multf divi divf modi modf ori andi eqi nei ltlti lti eqf nef ltf gti gtf lei lef gei gef indi inds
(CALL_DATA cd, tindex_t res, vindex_t op1, VALUE imm)
()
()
{
    if (RTL_FUNC_NAME(NAME_OF_CURRENT_INSN)(ec, reg_cfp, cd, get_temp_addr(reg_cfp, res), get_var_addr(reg_cfp, op1), imm)) {
	ec->cfp[1].pc += 5;
	RESTORE_REGS();
        set_default_sp(reg_cfp, reg_cfp->bp);
	NEXT_INSN();
    }
}

/* Unchanging immediate insns:  */
DEFINE_INSN
uplusi uplusf uminusi uminusf umulti umultf udivi udivf umodi umodf uori uandi ueqi ueqf unei unef ulti ultf ugti ugtf ulei ulef ugei ugef uindi uinds
(CALL_DATA cd, tindex_t res, vindex_t op1, VALUE imm)
()
()
{
    if (RTL_FUNC_NAME(NAME_OF_CURRENT_INSN)(ec, reg_cfp, cd, get_temp_addr(reg_cfp, res), get_var_addr(reg_cfp, op1), imm)) {
	ec->cfp[1].pc += 5;
	RESTORE_REGS();
        set_default_sp(reg_cfp, reg_cfp->bp);
	NEXT_INSN();
    }
}

/* Speculative immediate insns:  */
DEFINE_INSN
fplusf fminusf fmultf fdivf fmodf
(CALL_DATA _, tindex_t res, vindex_t op1, VALUE imm)
()
()
{
    enum ruby_vminsn_type new_insn;
    
    if (RTL_FUNC_NAME(NAME_OF_CURRENT_INSN)(reg_cfp, get_temp_addr(reg_cfp, res), get_var_addr(reg_cfp, op1), imm, &new_insn,
					 NULL, NULL)) {
	/* Change and re-execute the insn.  */
	vm_change_insn(reg_cfp->iseq, GET_PC(), new_insn);
	ADD_PC(-5);
    }
}

DEFINE_INSN
feqf fnef fltf fgtf flef fgef
(CALL_DATA _, tindex_t res, vindex_t op1, VALUE imm)
()
()
{
    enum ruby_vminsn_type new_insn;
    
    if (RTL_FUNC_NAME(NAME_OF_CURRENT_INSN)(reg_cfp, get_temp_addr(reg_cfp, res), get_var_addr(reg_cfp, op1), imm, &new_insn, NULL)) {
	/* Change and re-execute the insn.  */
	vm_change_insn(reg_cfp->iseq, GET_PC(), new_insn);
	ADD_PC(-5);
    }
}

DEFINE_INSN
ieqi inei iplusi iminusi imulti idivi imodi iori iandi ilti igti ilei igei aindi hindi hinds
(CALL_DATA _, tindex_t res, vindex_t op1, VALUE imm)
()
()
{
    enum ruby_vminsn_type new_insn;
    
    if (RTL_FUNC_NAME(NAME_OF_CURRENT_INSN)(reg_cfp, get_temp_addr(reg_cfp, res), get_var_addr(reg_cfp, op1), imm, &new_insn)) {
	/* Change and re-execute the insn.  */
	vm_change_insn(reg_cfp->iseq, GET_PC(), new_insn);
	ADD_PC(-5);
    }
}

/* General and unchanging insns:  */
DEFINE_INSN
indset uindset
(CALL_DATA cd, vindex_t op1, vindex_t op2, vindex_t op3)
()
()
{
    if (RTL_FUNC_NAME(NAME_OF_CURRENT_INSN)(ec, reg_cfp, cd, get_var_addr(reg_cfp, op1),
					    get_var_addr(reg_cfp, op2), get_var_addr(reg_cfp, op3))) {
	ec->cfp[1].pc += 5;
	RESTORE_REGS();
	set_default_sp(reg_cfp, reg_cfp->bp);
	NEXT_INSN();
    }
}

/* Speculative insns:  */
DEFINE_INSN
aindset hindset
(CALL_DATA _, vindex_t op1, vindex_t op2, vindex_t op3)
()
()
{
    enum ruby_vminsn_type new_insn;
    
    if (RTL_FUNC_NAME(NAME_OF_CURRENT_INSN)(reg_cfp, get_var_addr(reg_cfp, op1),
					    get_var_addr(reg_cfp, op2), get_var_addr(reg_cfp, op3), &new_insn)) {
	/* Change and re-execute the insn.  */
	vm_change_insn(reg_cfp->iseq, GET_PC(), new_insn);
	ADD_PC(-5);
    }
}

/* General and unchanging immediate insns:  */
DEFINE_INSN
indseti indsets uindseti uindsets
(CALL_DATA cd, vindex_t op1, VALUE imm, vindex_t op3)
()
()
{
    if (RTL_FUNC_NAME(NAME_OF_CURRENT_INSN)(ec, reg_cfp, cd, get_var_addr(reg_cfp, op1), imm, get_var_addr(reg_cfp, op3))) {
	ec->cfp[1].pc += 5;
	RESTORE_REGS();
	set_default_sp(reg_cfp, reg_cfp->bp);
	NEXT_INSN();
    }
}

/* Speculative immediate insns:  */
DEFINE_INSN
aindseti hindseti hindsets
(CALL_DATA _, vindex_t op1, VALUE imm, vindex_t op3)
()
()
{
    enum ruby_vminsn_type new_insn;
    
    if (RTL_FUNC_NAME(NAME_OF_CURRENT_INSN)(reg_cfp, get_var_addr(reg_cfp, op1), imm, get_var_addr(reg_cfp, op3), &new_insn)) {
	vm_change_insn(reg_cfp->iseq, GET_PC(), new_insn);
	ADD_PC(-5);
    }
}

DEFINE_INSN
goto
(OFFSET dst)
()
()
// attr bool leaf = false; /* has rb_threadptr_execute_interrupts() */
{
    goto_f(ec, reg_cfp);
    JUMP(dst);
}

/* First operand should be a label.  This is used in
   get_destination_insn for peephole optimizer in compile.c */
DEFINE_INSN
bf bt bnil
(OFFSET dst, vindex_t op)
()
()
// attr bool leaf = false; /* has rb_threadptr_execute_interrupts() */
{
    if (RTL_FUNC_NAME(NAME_OF_CURRENT_INSN)(ec, reg_cfp, get_var_addr(reg_cfp, op)))
	JUMP(dst);
}

DEFINE_INSN
btype
(OFFSET dst, rb_num_t type, vindex_t op)
()
()
// attr bool leaf = false; /* has rb_threadptr_execute_interrupts() */
{
    if (btype_f(ec, reg_cfp, type, get_var_addr(reg_cfp, op)))
	JUMP(dst);
}

DEFINE_INSN
cont_btcmp
(OFFSET dst, CALL_DATA cd, tindex_t res, vindex_t _, vindex_t _)
()
()
// attr bool leaf = false; /* has rb_threadptr_execute_interrupts() */
{
    VALUE val = *get_temp_addr(reg_cfp, res);

    if (RTEST(val)) {
	RUBY_VM_CHECK_INTS(ec);
	JUMP(dst);
    }
}

DEFINE_INSN
cont_bfcmp
(OFFSET dst, CALL_DATA cd, tindex_t res, vindex_t _, vindex_t _)
()
()
// attr bool leaf = false; /* has rb_threadptr_execute_interrupts() */
{
    VALUE val = *get_temp_addr(reg_cfp, res);

    if (! RTEST(val)) {
	RUBY_VM_CHECK_INTS(ec);
	JUMP(dst);
    }
}

/* The following insns are combined insns of (eq,ne,lt,gt,le,ge)[if] and (bt|bf):  */
DEFINE_INSN
bteq bfeq btne bfne btlt bflt btgt bfgt btle bfle btge bfge
(insn_t _, OFFSET dst, CALL_DATA cd, tindex_t res, vindex_t op1, vindex_t op2)
()
()
{
    VALUE val;
    int jmp_p = RTL_FUNC_NAME(NAME_OF_CURRENT_INSN)(ec, reg_cfp, cd, get_temp_addr(reg_cfp, res),
						    get_var_addr(reg_cfp, op1), get_var_addr(reg_cfp, op2), &val);

    if (val == Qundef) {
	ec->cfp[1].pc += 1; /* Execute cont_btcmp/cont_bfcmp after */
        RESTORE_REGS();
	set_default_sp(reg_cfp, reg_cfp->bp);
	NEXT_INSN();
    }
    else if (jmp_p)
	JUMP(dst);
}

/* Unchanging insns:  */
DEFINE_INSN
ubteq ubfeq ubtne ubfne ubtlt ubflt ubtgt ubfgt ubtle ubfle ubtge ubfge
(insn_t _, OFFSET dst, CALL_DATA cd, tindex_t res, vindex_t op1, vindex_t op2)
()
()
{
    VALUE val;
    int jmp_p = RTL_FUNC_NAME(NAME_OF_CURRENT_INSN)(ec, reg_cfp, cd, get_temp_addr(reg_cfp, res),
						    get_var_addr(reg_cfp, op1), get_var_addr(reg_cfp, op2), &val);

    if (val == Qundef) {
	ec->cfp[1].pc += 1; /* Execute cont_btcmp/cont_bfcmp after */
        RESTORE_REGS();
	set_default_sp(reg_cfp, reg_cfp->bp);
	NEXT_INSN();
    }
    else if (jmp_p)
	JUMP(dst);
}

/* Speculative integer insns:  */
DEFINE_INSN
ibteq ibfeq ibtne ibfne ibtlt ibflt ibtgt ibfgt ibtle ibfle ibtge ibfge
(insn_t _, OFFSET dst, CALL_DATA _, tindex_t res, vindex_t op1, vindex_t op2)
()
()
{
    VALUE val;
    enum ruby_vminsn_type new_insn;
    int jmp_p = RTL_FUNC_NAME(NAME_OF_CURRENT_INSN)(reg_cfp, get_temp_addr(reg_cfp, res),
						    get_var_addr(reg_cfp, op1), get_var_addr(reg_cfp, op2), &val, &new_insn);

    if (val == Qundef) {
	/* Change and re-execute the insn.  */
	vm_change_insn(reg_cfp->iseq, GET_PC(), new_insn);
	ADD_PC(-7);
    }
    else if (jmp_p)
	JUMP(dst);
}

/* Speculative floating point insns:  */
DEFINE_INSN
fbteq fbfeq fbtne fbfne fbtlt fbflt fbtgt fbfgt fbtle fbfle fbtge fbfge
(insn_t _, OFFSET dst, CALL_DATA _, tindex_t res, vindex_t op1, vindex_t op2)
()
()
{
    VALUE val;
    enum ruby_vminsn_type new_insn;
    int jmp_p = RTL_FUNC_NAME(NAME_OF_CURRENT_INSN)(reg_cfp, get_temp_addr(reg_cfp, res),
						    get_var_addr(reg_cfp, op1), get_var_addr(reg_cfp, op2), &val, &new_insn,
						    NULL, NULL);

    if (val == Qundef) {
	/* Change and re-execute the insn.  */
	vm_change_insn(reg_cfp->iseq, GET_PC(), new_insn);
	ADD_PC(-7);
    }
    else if (jmp_p)
	JUMP(dst);
}

DEFINE_INSN
bteqi bfeqi btnei bfnei btlti bflti btgti bfgti btlei bflei btgei bfgei bteqf bfeqf btnef bfnef btltf bfltf btgtf bfgtf btlef bflef btgef bfgef
(insn_t _, OFFSET dst, CALL_DATA cd, tindex_t res, vindex_t op1, VALUE imm)
()
()
{
    VALUE val;
    int jmp_p = RTL_FUNC_NAME(NAME_OF_CURRENT_INSN)(ec, reg_cfp, cd, get_temp_addr(reg_cfp, res),
						    get_var_addr(reg_cfp, op1), imm, &val);

    if (val == Qundef) {
	ec->cfp[1].pc += 1; /* Execute cont_btcmp/cont_bfcmp after */
        RESTORE_REGS();
	set_default_sp(reg_cfp, reg_cfp->bp);
	NEXT_INSN();
    } else if (jmp_p)
	JUMP(dst);
}

/* Unchanging immediate insns:  */
DEFINE_INSN
ubteqi ubfeqi ubtnei ubfnei ubtlti ubflti ubtgti ubfgti ubtlei ubflei ubtgei ubfgei ubteqf ubfeqf ubtnef ubfnef ubtltf ubfltf ubtgtf ubfgtf ubtlef ubflef ubtgef ubfgef
(insn_t _, OFFSET dst, CALL_DATA cd, tindex_t res, vindex_t op1, VALUE imm)
()
()
{
    VALUE val;
    int jmp_p = RTL_FUNC_NAME(NAME_OF_CURRENT_INSN)(ec, reg_cfp, cd, get_temp_addr(reg_cfp, res),
						    get_var_addr(reg_cfp, op1), imm, &val);

    if (val == Qundef) {
	ec->cfp[1].pc += 1; /* Execute cont_btcmp/cont_bfcmp after */
        RESTORE_REGS();
	set_default_sp(reg_cfp, reg_cfp->bp);
	NEXT_INSN();
    } else if (jmp_p)
	JUMP(dst);
}

/* Speculative immediate integer insns:  */
DEFINE_INSN
ibteqi ibfeqi ibtnei ibfnei ibtlti ibflti ibtgti ibfgti ibtlei ibflei ibtgei ibfgei
(insn_t _, OFFSET dst, CALL_DATA _, tindex_t res, vindex_t op1, VALUE imm)
()
()
{
    VALUE val;
    enum ruby_vminsn_type new_insn;
    int jmp_p = RTL_FUNC_NAME(NAME_OF_CURRENT_INSN)(reg_cfp, get_temp_addr(reg_cfp, res), get_var_addr(reg_cfp, op1), imm, &val, &new_insn);

    if (val == Qundef) {
	/* Change and re-execute the insn.  */
	vm_change_insn(reg_cfp->iseq, GET_PC(), new_insn);
	ADD_PC(-7);
    }
    else if (jmp_p)
	JUMP(dst);
}

/* Speculative immediate floating point insns:  */
DEFINE_INSN
fbteqf fbfeqf fbtnef fbfnef fbtltf fbfltf fbtgtf fbfgtf fbtlef fbflef fbtgef fbfgef
(insn_t _, OFFSET dst, CALL_DATA _, tindex_t res, vindex_t op1, VALUE imm)
()
()
{
    VALUE val;
    enum ruby_vminsn_type new_insn;
    int jmp_p = RTL_FUNC_NAME(NAME_OF_CURRENT_INSN)(reg_cfp, get_temp_addr(reg_cfp, res), get_var_addr(reg_cfp, op1), imm,
						    &val, &new_insn, NULL);

    if (val == Qundef) {
	/* Change and re-execute the insn.  */
	
	vm_change_insn(reg_cfp->iseq, GET_PC(), new_insn);
	ADD_PC(-7);
    }
    else if (jmp_p)
	JUMP(dst);
}

DEFINE_INSN
freeze_string
(vindex_t op, VALUE debug_info)
()
()
{
    freeze_string_f(reg_cfp, get_var_addr(reg_cfp, op), debug_info);
}

DEFINE_INSN
to_string
(tindex_t res, vindex_t op1, tindex_t op2)
()
()
{
    to_string_f(reg_cfp, get_temp_addr(reg_cfp, res), get_var_addr(reg_cfp, op1), get_temp_addr(reg_cfp, op2));
}

DEFINE_INSN
concat_strings
(tindex_t start, rb_num_t cnt)
()
()
{
    concat_strings_f(reg_cfp, get_temp_addr(reg_cfp, start), cnt);
}

DEFINE_INSN
to_regexp
(sindex_t start, rb_num_t opt, rb_num_t cnt)
()
()
// attr bool leaf = true; /* yes it is */
{
    to_regexp_f(reg_cfp, start, opt, cnt);
}

DEFINE_INSN
defined_p
(tindex_t res, vindex_t op, rb_num_t op_type, VALUE obj, VALUE needstr)
()
()
// attr bool leaf = leafness_of_defined(op_type);
{
    defined_p_f(ec, reg_cfp, get_temp_addr(reg_cfp, res), get_var_addr(reg_cfp, op), op_type, obj, needstr);
}

DEFINE_INSN
val_defined_p
(tindex_t res, VALUE v, rb_num_t op_type, VALUE obj, VALUE needstr)
()
()
// attr bool leaf = leafness_of_defined(op_type);
{
    val_defined_p_f(ec, reg_cfp, get_temp_addr(reg_cfp, res), v, op_type, obj, needstr);
}

DEFINE_INSN
str_freeze_call str_uminus
(CALL_DATA cd, tindex_t res, VALUE str)
()
()
{
    if (RTL_FUNC_NAME(NAME_OF_CURRENT_INSN)(ec, reg_cfp, cd, get_temp_addr(reg_cfp, res), str)) {
	ec->cfp[1].pc += 4;
	RESTORE_REGS();
	set_default_sp(reg_cfp, reg_cfp->bp);
	NEXT_INSN();
    }
}

DEFINE_INSN
temp_ret
(tindex_t op)
()
()
// attr bool leaf = false; /* has rb_threadptr_execute_interrupts() */
// attr bool handles_sp = true;
{
    VALUE val;

    if (temp_ret_f(ec, reg_cfp, get_temp_addr(reg_cfp, op), &val))
	return val;
    RESTORE_REGS();
    finish_ret(reg_cfp, val);
}

DEFINE_INSN
loc_ret
(vindex_t op)
()
()
// attr bool leaf = false; /* has rb_threadptr_execute_interrupts() */
// attr bool handles_sp = true;
{
    VALUE val;

    if (loc_ret_f(ec, reg_cfp, get_loc_addr(reg_cfp, op), &val))
	return val;
    RESTORE_REGS();
    finish_ret(reg_cfp, val);
}

DEFINE_INSN
val_ret
(VALUE val)
()
()
// attr bool leaf = false; /* has rb_threadptr_execute_interrupts() */
// attr bool handles_sp = true;
{
    if (val_ret_f(ec, reg_cfp, val, &val))
	return val;
    RESTORE_REGS();
    finish_ret(reg_cfp, val);
}

DEFINE_INSN
simple_call simple_call_self
(CALL_DATA cd, sindex_t call_start)
()
()
// attr bool handles_sp = true;
// attr bool leaf = false; /* Of course it isn't. */
{
    struct rb_calling_info calling;

    RTL_FUNC_NAME(NAME_OF_CURRENT_INSN)(ec, reg_cfp, &calling, cd, call_start);
    RTL_CALL_METHOD(&calling, cd);
}

DEFINE_INSN
simple_call_recv
(CALL_DATA cd, sindex_t call_start, vindex_t recv_op)
()
()
// attr bool handles_sp = true;
// attr bool leaf = false; /* Of course it isn't. */
{
    struct rb_calling_info calling;

    simple_call_recv_f(ec, reg_cfp, &calling, cd, call_start, get_var_addr(reg_cfp, recv_op));
    RTL_CALL_METHOD(&calling, cd);
}

DEFINE_INSN
call vmcore_call call_self
(CALL_DATA cd, sindex_t call_start, ISEQ blockiseq)
()
()
// attr bool handles_sp = true;
// attr bool leaf = false; /* Of course it isn't. */
{
    struct rb_calling_info calling;

    RTL_FUNC_NAME(NAME_OF_CURRENT_INSN)(ec, reg_cfp, &calling, cd, call_start, blockiseq);
    RTL_CALL_METHOD(&calling, cd);
}

DEFINE_INSN
call_recv
(CALL_DATA cd, sindex_t call_start, ISEQ blockiseq, vindex_t recv_op)
()
()
// attr bool handles_sp = true;
// attr bool leaf = false; /* Of course it isn't. */
{
    struct rb_calling_info calling;

    call_recv_f(ec, reg_cfp, &calling, cd, call_start, blockiseq, get_var_addr(reg_cfp, recv_op));
    RTL_CALL_METHOD(&calling, cd);
}

DEFINE_INSN
call_c_func
(rb_insn_func_t funcptr, sindex_t args_num)
()
()
// attr bool leaf = false; /* anything can happen inside */
// attr bool handles_sp = true;
{
    /* SP here is always on the stack beginning.  */
    reg_cfp->sp = reg_cfp->bp + 1 + args_num;
    reg_cfp = (funcptr)(ec, reg_cfp);

    if (reg_cfp == 0) {
	VALUE err = ec->errinfo;
	ec->errinfo = Qnil;
	THROW_EXCEPTION(err);
    }

    RESTORE_REGS();
    set_default_sp(reg_cfp, reg_cfp->bp);
}

DEFINE_INSN
call_block
(CALL_DATA cd, sindex_t call_start)
()
()
// attr bool leaf = false; /* Of course it isn't. */
// attr bool handles_sp = true;
{
    VALUE val = call_block_f(ec, reg_cfp, cd, call_start);
    if (val == Qundef) {
        RTL_EXEC_EC_CFP(val);
    } else {
	*get_temp_addr(reg_cfp, call_start) = val;
    }
    set_default_sp(reg_cfp, reg_cfp->bp);
}

DEFINE_INSN
call_super_val
(CALL_DATA cd, sindex_t call_start, ISEQ blockiseq, VALUE rec_val)
()
()
// attr bool handles_sp = true;
// attr bool leaf = false; /* Of course it isn't. */
{
    struct rb_calling_info calling;

    call_super_val_f(ec, reg_cfp, &calling, cd, call_start, blockiseq, rec_val);
    RTL_CALL_METHOD(&calling, cd);
}

DEFINE_INSN
call_super
(CALL_DATA cd, sindex_t call_start, ISEQ blockiseq, vindex_t rec_op)
()
()
// attr bool handles_sp = true;
// attr bool leaf = false; /* Of course it isn't. */
{
    struct rb_calling_info calling;

    call_super_f(ec, reg_cfp, &calling, cd, call_start, blockiseq, get_var_addr(reg_cfp, rec_op));
    RTL_CALL_METHOD(&calling, cd);
}

DEFINE_INSN
make_range
(tindex_t res, vindex_t op1, vindex_t op2, rb_num_t flag)
()
()
// attr bool leaf = false; /* see also: range.c:range_init() */
{
    make_range_f(reg_cfp, get_temp_addr(reg_cfp, res), get_var_addr(reg_cfp, op1), get_var_addr(reg_cfp, op2), flag);
}

DEFINE_INSN
make_array
(tindex_t res, sindex_t start, rb_num_t num)
()
()
// attr bool leaf = false; /* has rb_hash_key_str(), rb_funcall() */
{
    make_array_f(reg_cfp, get_temp_addr(reg_cfp, res), start, num);
}

DEFINE_INSN
make_hash new_array_min new_array_max
(tindex_t res, sindex_t start, rb_num_t num)
()
()
// attr bool leaf = false; /* has rb_hash_key_str(), rb_funcall() */
{
    RTL_FUNC_NAME(NAME_OF_CURRENT_INSN)(reg_cfp, get_temp_addr(reg_cfp, res), start, num);
}

DEFINE_INSN
clone_array
(tindex_t res, VALUE arr)
()
()
{
    clone_array_f(reg_cfp, get_temp_addr(reg_cfp, res), arr);
}

/* op1 is always in a temporary variable and it is a location of the
   result too.  */
DEFINE_INSN
spread_array
(vindex_t op1, rb_num_t num, rb_num_t flag)
()
()
// attr bool leaf = false; /* has rb_check_array_type() */
{
    spread_array_f(reg_cfp, get_var_addr(reg_cfp, op1), num, flag);
}

DEFINE_INSN
splat_array
(tindex_t res, vindex_t arr, VALUE flag)
()
()
// attr bool leaf = false; /* has rb_check_array_type() */
{
    splat_array_f(reg_cfp, get_temp_addr(reg_cfp, res), get_var_addr(reg_cfp, arr), flag);
}


DEFINE_INSN
concat_array
(tindex_t res, vindex_t op1, vindex_t op2)
()
()
// attr bool leaf = false; /* has rb_check_array_type() */
{
    concat_array_f(reg_cfp, get_temp_addr(reg_cfp, res), get_var_addr(reg_cfp, op1), get_var_addr(reg_cfp, op2));
}

DEFINE_INSN
check_keyword
(tindex_t res, sindex_t kw_bits_index, rb_num_t keyword_index)
()
()
{
    check_keyword_f(reg_cfp, get_temp_addr(reg_cfp, res), kw_bits_index, keyword_index);
}

DEFINE_INSN
bkw
(OFFSET dst, sindex_t kw_bits_index, rb_num_t keyword_index)
()
()
{
    if (bkw_f(ec, reg_cfp, kw_bits_index, keyword_index))
	JUMP(dst);
}

DEFINE_INSN
check_type
(tindex_t res, vindex_t op, rb_num_t type)
()
()
{
    check_type_f(reg_cfp, get_temp_addr(reg_cfp, res), get_var_addr(reg_cfp, op), type);
}

DEFINE_INSN
check_match
(tindex_t res, vindex_t op1, vindex_t op2, rb_num_t flag)
()
()
// attr bool leaf = leafness_of_checkmatch(flag);
{
    check_match_f(ec, reg_cfp, get_temp_addr(reg_cfp, res), get_var_addr(reg_cfp, op1), get_var_addr(reg_cfp, op2), flag);
}

DEFINE_INSN
bt_match
(OFFSET dst, tindex_t res, vindex_t op1, vindex_t op2, rb_num_t flag)
()
()
{
    if (bt_match_f(ec, reg_cfp, get_temp_addr(reg_cfp, res), get_var_addr(reg_cfp, op1), get_var_addr(reg_cfp, op2), flag))
	JUMP(dst);
}

DEFINE_INSN
case_dispatch
(vindex_t op, CDHASH hash, OFFSET else_offset)
()
()
{
    OFFSET dst;

    if ((dst = case_dispatch_f(reg_cfp, get_var_addr(reg_cfp, op), hash, else_offset)) != 0)
	JUMP(dst);
}

DEFINE_INSN
regexp_match1
(tindex_t res, VALUE regex, vindex_t str_op)
()
()
// attr bool leaf = BASIC_OP_UNREDEFINED_P(BOP_MATCH, REGEXP_REDEFINED_OP_FLAG);
{
    regexp_match1_f(reg_cfp, get_temp_addr(reg_cfp, res), regex, get_var_addr(reg_cfp, str_op));
}

DEFINE_INSN
regexp_match2
(CALL_DATA cd, tindex_t res, vindex_t str_op, vindex_t regex_op)
()
()
{
    if (regexp_match2_f(ec, reg_cfp, cd, get_temp_addr(reg_cfp, res), get_var_addr(reg_cfp, str_op), get_var_addr(reg_cfp, regex_op))) {
	ec->cfp[1].pc += 5;
	RESTORE_REGS();
	set_default_sp(reg_cfp, reg_cfp->bp);
	NEXT_INSN();
    }
}

DEFINE_INSN
raise_except
(vindex_t op, rb_num_t throw_state)
()
()
// attr bool leaf = false; /* has rb_threadptr_execute_interrupts() */
// attr bool handles_sp = true;
{
    VALUE val = raise_except_f(ec, reg_cfp, get_var_addr(reg_cfp, op), throw_state);
    THROW_EXCEPTION(val);
    /* unreachable */
}

/* Increase PC first for correct exception processing.  */
DEFINE_INSN
raise_except_val
(VALUE throwobj, rb_num_t throw_state)
()
()
// attr bool leaf = false; /* has rb_threadptr_execute_interrupts() */
// attr bool handles_sp = true;
{
    VALUE val = raise_except_val_f(ec, reg_cfp, throwobj, throw_state);
    THROW_EXCEPTION(val);
    /* unreachable */
}

DEFINE_INSN
trace_coverage
(rb_num_t nf, VALUE data)
()
()
{
    trace_coverage_f(ec, reg_cfp, nf, data);
}

DEFINE_INSN
define_class
(ID id, ISEQ class_iseq, rb_num_t flags, vindex_t op1, vindex_t op2, sindex_t stack_top)
()
()
// attr bool handles_sp = true;
{
    define_class(ec, reg_cfp, id, class_iseq, flags, get_var_addr(reg_cfp, op1), get_var_addr(reg_cfp, op2), stack_top);
    RESTORE_REGS();
    set_default_sp(reg_cfp, reg_cfp->bp);
}

DEFINE_INSN
run_once
(tindex_t res, ISEQ iseq, ISE ise)
()
()
{
    run_once_f(ec, reg_cfp, get_temp_addr(reg_cfp, res), iseq, ise);
}
